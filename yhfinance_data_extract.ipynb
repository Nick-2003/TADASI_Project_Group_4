{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "386d0bca-7073-432f-a327-34bf23dd0ba1",
   "metadata": {},
   "source": [
    "# Data Extraction from `yhfinance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb6c7eb7-5551-465d-8d20-76737438f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b345220-9770-499b-9fe4-eba0972f8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4c5bb2c-5359-4924-9c0d-b03ec19f5170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SAndP500_Wikipedia_Scrape():\n",
    "    \"\"\"\n",
    "    Fetch S&P500 tickers and corresponding data from Wikipedia\n",
    "    \"\"\"\n",
    "    print(\"Fetching from Wikipedia...\")\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    # Download HTML, parse it to find all tables and create corresponding pandas DataFrames and return list of DataFrames\n",
    "    response = requests.get(url, headers=headers)\n",
    "    tables = pd.read_html(StringIO(response.text))\n",
    "    sp500_table = tables[0]\n",
    "    \n",
    "    # Create DataFrame with relevant info\n",
    "    df = pd.DataFrame({\n",
    "        'Ticker': sp500_table['Symbol'].tolist(),\n",
    "        'Company': sp500_table['Security'].tolist(),\n",
    "        'Sector': sp500_table['GICS Sector'].tolist(),\n",
    "        'Industry': sp500_table['GICS Sub-Industry'].tolist()\n",
    "    })\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f443982b-1634-4f03-85dc-1552e3704214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NASDAQ100_Wikipedia_Scrape():\n",
    "    \"\"\"\n",
    "    Fetch NASDAQ100 tickers and corresponding data from Wikipedia\n",
    "    \"\"\"\n",
    "    print(\"Fetching from Wikipedia...\")\n",
    "    url = 'https://en.wikipedia.org/wiki/Nasdaq-100'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    # Download HTML, parse it to find all tables and create corresponding pandas DataFrames and return list of DataFrames\n",
    "    response = requests.get(url, headers=headers)\n",
    "    tables = pd.read_html(StringIO(response.text))\n",
    "\n",
    "    # Find NASDAQ table\n",
    "    for index, table in enumerate(tables):\n",
    "        if 'Ticker' in table.columns and len(table) > 90:\n",
    "            ndaq100_table = tables[index]\n",
    "    \n",
    "    # Create DataFrame with relevant info\n",
    "    df = pd.DataFrame({\n",
    "        'Ticker': ndaq100_table['Ticker'].tolist(),\n",
    "        'Company': ndaq100_table['Company'].tolist(),\n",
    "        'Sector': ndaq100_table['ICB Sector'].tolist(),\n",
    "        'Industry': ndaq100_table['ICB Industry'].tolist()\n",
    "    })\n",
    "\n",
    "    # Add NDAQ manually\n",
    "    ndaq_row = pd.DataFrame({\n",
    "        'Ticker': [\"NDAQ\"],\n",
    "        'Company': [\"Nasdaq, Inc.\"],\n",
    "        'Sector': [\"Financial Services\"],\n",
    "        'Industry': [\"Stock Exchange\"]\n",
    "    })\n",
    "\n",
    "    df = pd.concat([df, ndaq_row], ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b9bfbfa-2221-4511-81be-6586db97ce5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching from Wikipedia...\n",
      " Successfully fetched 103 NASDAQ-100 tickers!\n",
      "\n",
      "============================================================\n",
      "Total tickers: 103\n",
      "\n",
      "First 10 tickers:\n",
      "Ticker                 Company                 Sector                        Industry\n",
      "  ADBE              Adobe Inc.             Technology               Computer Software\n",
      "   AMD  Advanced Micro Devices             Technology                  Semiconductors\n",
      "  ABNB                  Airbnb Consumer Discretionary Diversified Commercial Services\n",
      " GOOGL Alphabet Inc. (Class A) Communication Services               Computer Software\n",
      "  GOOG Alphabet Inc. (Class C) Communication Services               Computer Software\n",
      "  AMZN                  Amazon Consumer Discretionary  Catalog/Specialty Distribution\n",
      "   AEP American Electric Power              Utilities              Electric Utilities\n",
      "  AMGN                   Amgen            Health Care                   Biotechnology\n",
      "   ADI          Analog Devices             Technology                  Semiconductors\n",
      "  AAPL              Apple Inc.             Technology          Computer Manufacturing\n",
      "\n",
      "============================================================\n",
      "Sector Distribution:\n",
      "============================================================\n",
      "Sector\n",
      "Technology                43\n",
      "Consumer Discretionary    18\n",
      "Industrials               11\n",
      "Health Care               10\n",
      "Consumer Staples           6\n",
      "Utilities                  4\n",
      "Communication Services     3\n",
      "Telecommunications         3\n",
      "Real Estate                2\n",
      "Energy                     1\n",
      "Basic Materials            1\n",
      "Financial Services         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ndaq100df = NASDAQ100_Wikipedia_Scrape()\n",
    "    ticker_list = ndaq100df['Ticker'].tolist()\n",
    "    print(f\" Successfully fetched {len(ndaq100df)} NASDAQ-100 tickers!\")\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Total tickers: {len(ndaq100df)}\")\n",
    "    print(\"\\nFirst 10 tickers:\")\n",
    "    print(ndaq100df.head(10).to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Sector Distribution:\")\n",
    "    print(\"=\"*60)\n",
    "    print(ndaq100df['Sector'].value_counts())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Python scrape failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6503afcd-f74d-4195-85f9-f49f5bca2a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker_list = [\"AAPL\", \"META\", \"NDAQ\", \"SPY\",]\n",
    "# company_list = []\n",
    "\n",
    "# for ticker_symbol in ticker_list:\n",
    "#     try: \n",
    "#         stock = yf.Ticker(ticker_symbol)\n",
    "#         company_name = stock.info.get('longName', 'N/A')\n",
    "#         company_list.append(company_name)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching {ticker}: {e}\")\n",
    "#         company_list.append(\"Error\")\n",
    "\n",
    "# tick_comp_df = pd.DataFrame({\n",
    "#     'Ticker': ticker_list,\n",
    "#     'Company': company_list\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26536684-ed5b-4b0b-b71b-ee5c2a7157b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_62652/2776169727.py:3: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker_list, start=start_date, end=end_date, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date Ticker       Close        High         Low        Open  \\\n",
      "0 2022-10-31   AAPL  150.957077  151.843100  149.559146  150.779881   \n",
      "1 2022-10-31   ABNB  106.910004  113.800003  106.669998  113.059998   \n",
      "2 2022-10-31   ADBE  318.500000  325.579987  317.420013  323.489990   \n",
      "3 2022-10-31    ADI  135.263504  136.458521  133.347708  136.392125   \n",
      "4 2022-10-31    ADP  226.601562  227.248462  224.501499  225.560901   \n",
      "5 2022-10-31   ADSK  214.300003  216.289993  214.000000  214.759995   \n",
      "6 2022-10-31    AEP   78.322487   79.632020   77.823620   79.596386   \n",
      "7 2022-10-31   AMAT   85.900391   86.980349   85.287445   86.454963   \n",
      "8 2022-10-31    AMD   60.060001   61.860001   59.529999   60.750000   \n",
      "9 2022-10-31   AMGN  245.694199  247.021039  243.558512  244.649084   \n",
      "\n",
      "       Volume  \n",
      "0  97943200.0  \n",
      "1  10733800.0  \n",
      "2   3253200.0  \n",
      "3   3078300.0  \n",
      "4   1711400.0  \n",
      "5    965000.0  \n",
      "6   4104000.0  \n",
      "7   6875400.0  \n",
      "8  73274100.0  \n",
      "9   3033600.0  \n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.datetime(2022, 10, 29)\n",
    "end_date = datetime.datetime(2025, 10, 29)\n",
    "data = yf.download(ticker_list, start=start_date, end=end_date, progress=False)\n",
    "data = data.stack(level='Ticker', future_stack=True).reset_index()\n",
    "data.columns.name = None\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d149d89-3bda-4cdd-8d03-9a6d123d4d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate RSI\n",
    "def calculate_rsi(series, window=14):\n",
    "    delta = series.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "# Function to calculate Aroon\n",
    "def add_aroon(data, period=14, ticker_col=None):\n",
    "    \"\"\"\n",
    "    Add Aroon Up and Aroon Down indicators to data\n",
    "    \n",
    "    Parameters:\n",
    "        data (DataFrame): Must have 'High' and 'Low' columns\n",
    "        period (int): Lookback period (default: 14)\n",
    "        ticker_col (str): Column name for ticker if multi-ticker data\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Data with 'Aroon_Up' and 'Aroon_Down' columns added\n",
    "        \n",
    "    Note: Intermediate columns are automatically removed\n",
    "    \"\"\"\n",
    "    \n",
    "    df = data.copy()\n",
    "    \n",
    "    def calc_aroon(group):\n",
    "        # Periods since highest high\n",
    "        periods_high = group['High'].rolling(window=period).apply(\n",
    "            lambda x: period - 1 - np.argmax(x), raw=True\n",
    "        )\n",
    "        \n",
    "        # Periods since lowest low  \n",
    "        periods_low = group['Low'].rolling(window=period).apply(\n",
    "            lambda x: period - 1 - np.argmin(x), raw=True\n",
    "        )\n",
    "        \n",
    "        # Calculate Aroon indicators\n",
    "        group['Aroon_Up'] = ((period - periods_high) / period)\n",
    "        group['Aroon_Down'] = ((period - periods_low) / period)\n",
    "        \n",
    "        return group\n",
    "    \n",
    "    # Apply to each ticker or entire dataset\n",
    "    if ticker_col and ticker_col in df.columns:\n",
    "        df = df.groupby(ticker_col, as_index=False, group_keys=False).apply(calc_aroon)\n",
    "    else:\n",
    "        df = calc_aroon(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca4c5bd8-9257-40e9-abc7-77184fdb57e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect RSI divergence\n",
    "def rsi_divergence(group, lookback=14):\n",
    "    \"\"\"\n",
    "    Detect RSI divergence for each row in a group\n",
    "    Returns Series with divergence directions (1, -1, or 0)\n",
    "    \"\"\"\n",
    "    result = pd.Series(index=group.index, dtype=object)\n",
    "    \n",
    "    for i in range(len(group)):\n",
    "        # Need at least lookback periods\n",
    "        if i < lookback:\n",
    "            result.iloc[i] = None\n",
    "            continue\n",
    "        \n",
    "        # Get the lookback window (including current point)\n",
    "        start_idx = max(0, i - lookback)\n",
    "        price_window = group['Close'].iloc[start_idx:i+1]\n",
    "        rsi_window = group['RSI'].iloc[start_idx:i+1]\n",
    "        \n",
    "        # Current values\n",
    "        current_price = group['Close'].iloc[i]\n",
    "        current_rsi = group['RSI'].iloc[i]\n",
    "        \n",
    "        # Skip if RSI is NaN\n",
    "        if pd.isna(current_rsi):\n",
    "            result.iloc[i] = None\n",
    "            continue\n",
    "        \n",
    "        # Find min and max in the window (excluding current point)\n",
    "        price_window_prev = price_window.iloc[:-1]\n",
    "        rsi_window_prev = rsi_window.iloc[:-1]\n",
    "        \n",
    "        if len(price_window_prev) == 0:\n",
    "            result.iloc[i] = None\n",
    "            continue\n",
    "        \n",
    "        # Get indices of min/max\n",
    "        price_min_idx = price_window_prev.idxmin()\n",
    "        price_max_idx = price_window_prev.idxmax()\n",
    "        \n",
    "        # Bullish Divergence: Price making lower lows, RSI making higher lows\n",
    "        if price_min_idx != group.index[i]:  # Min is not at current point\n",
    "            prev_price_low = price_window_prev.loc[price_min_idx]\n",
    "            prev_rsi_at_price_low = group.loc[price_min_idx, 'RSI']\n",
    "            \n",
    "            if pd.notna(prev_rsi_at_price_low) and current_price < prev_price_low and current_rsi > prev_rsi_at_price_low:\n",
    "                result.iloc[i] = 1\n",
    "                continue\n",
    "        \n",
    "        # Bearish Divergence: Price making higher highs, RSI making lower highs\n",
    "        if price_max_idx != group.index[i]:  # Max is not at current point\n",
    "            prev_price_high = price_window_prev.loc[price_max_idx]\n",
    "            prev_rsi_at_price_high = group.loc[price_max_idx, 'RSI']\n",
    "            \n",
    "            if pd.notna(prev_rsi_at_price_high) and current_price > prev_price_high and current_rsi < prev_rsi_at_price_high:\n",
    "                result.iloc[i] = -1\n",
    "                continue\n",
    "        \n",
    "        result.iloc[i] = 0\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1e43497-bab8-4bae-8ff0-fcba76fa1b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_drawdowns(df, lookback_period=100, date_col='Date', ticker_col='Ticker', close_col='Close'):\n",
    "    \"\"\"\n",
    "    Calculate rolling drawdown from peak for each ticker at each date.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with columns: Date, Ticker, Open, High, Low, Close\n",
    "    lookback_period : int, default=100\n",
    "        Number of periods to look back for peak calculation\n",
    "    date_col : str, default='Date'\n",
    "        Name of the date column\n",
    "    ticker_col : str, default='Ticker'\n",
    "        Name of the ticker column\n",
    "    close_col : str, default='Close'\n",
    "        Name of the close price column\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Original dataframe with added 'Drawdown_%' column\n",
    "    \n",
    "    Formula:\n",
    "    --------\n",
    "    Drawdown = ((Current Price - Peak Price in Window) / Peak Price) × 100\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> df = pd.DataFrame({\n",
    "    ...     'Date': pd.date_range('2024-01-01', periods=150, freq='D'),\n",
    "    ...     'Ticker': ['AAPL']*150,\n",
    "    ...     'Close': np.random.randn(150).cumsum() + 100\n",
    "    ... })\n",
    "    >>> df_with_dd = calculate_drawdowns(df, lookback_period=50)\n",
    "    >>> print(df_with_dd[['Date', 'Ticker', 'Close', 'Drawdown_%']].tail())\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a copy to avoid modifying original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure date column is datetime\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    \n",
    "    # Sort by ticker and date\n",
    "    df = df.sort_values([ticker_col, date_col]).reset_index(drop=True)\n",
    "    \n",
    "    # Calculate drawdown for each ticker separately\n",
    "    def calc_dd_for_ticker(ticker_df):\n",
    "        \"\"\"Calculate drawdown for a single ticker\"\"\"\n",
    "        # Get closing prices\n",
    "        prices = ticker_df[close_col].values\n",
    "        \n",
    "        # Calculate rolling maximum (peak) within lookback window\n",
    "        drawdowns = []\n",
    "        for i in range(len(prices)):\n",
    "            # Determine lookback window\n",
    "            start_idx = max(0, i - lookback_period + 1)\n",
    "            window_prices = prices[start_idx:i+1]\n",
    "            \n",
    "            # Find peak in window\n",
    "            peak = np.max(window_prices)\n",
    "            \n",
    "            # Calculate drawdown\n",
    "            current_price = prices[i]\n",
    "            if peak > 0:\n",
    "                dd = ((current_price - peak) / peak) * 100\n",
    "            else:\n",
    "                dd = 0.0\n",
    "            \n",
    "            drawdowns.append(dd)\n",
    "        \n",
    "        ticker_df['Drawdown_%'] = drawdowns\n",
    "        return ticker_df\n",
    "    \n",
    "    # Apply to each ticker\n",
    "    df = df.groupby(ticker_col, group_keys=False).apply(calc_dd_for_ticker)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cae7e6e9-ca51-476b-8e57-ad41d8fb8b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_strength(df, benchmark_ticker, lookback_period=7, \n",
    "                                date_col='Date', ticker_col='Ticker', close_col='Close'):\n",
    "    \"\"\"\n",
    "    Calculate Relative Strength of each ticker vs benchmark using ONLY historical data.\n",
    "    \n",
    "    CRITICAL: For each date, only uses data from EARLIER dates (no look-ahead bias).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with columns: Date, Ticker, Open, High, Low, Close\n",
    "    benchmark_ticker : str\n",
    "        Ticker symbol to use as benchmark (e.g., 'NDAQ', 'SPY')\n",
    "    lookback_period : int, default=7\n",
    "        Number of HISTORICAL periods to calculate RS over\n",
    "    date_col : str, default='Date'\n",
    "        Name of the date column\n",
    "    ticker_col : str, default='Ticker'\n",
    "        Name of the ticker column\n",
    "    close_col : str, default='Close'\n",
    "        Name of the close price column\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Original dataframe with added 'RS_%' column\n",
    "    \n",
    "    Temporal Logic:\n",
    "    ---------------\n",
    "    For date T, RS calculation uses:\n",
    "    - Current ratio: Asset[T] / Benchmark[T]\n",
    "    - Historical ratio: Asset[T-lookback] / Benchmark[T-lookback]\n",
    "    - Both Asset and Benchmark data must exist for dates T and T-lookback\n",
    "    \n",
    "    Formula:\n",
    "    --------\n",
    "    RS_T = ((Ratio_T - Ratio_(T-lookback)) / Ratio_(T-lookback)) × 100\n",
    "    where Ratio_T = Asset_Price_T / Benchmark_Price_T\n",
    "    \n",
    "    Example Timeline:\n",
    "    -----------------\n",
    "    Date          Asset    Benchmark   Ratio    RS (7-day)\n",
    "    2024-01-01    150      100         1.50     N/A (need 7 days history)\n",
    "    2024-01-02    152      101         1.505    N/A\n",
    "    ...\n",
    "    2024-01-08    160      105         1.524    RS = ((1.524-1.50)/1.50)*100 = +1.6%\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> df = pd.DataFrame({\n",
    "    ...     'Date': pd.date_range('2024-01-01', periods=30, freq='D').tolist() * 2,\n",
    "    ...     'Ticker': ['AAPL']*30 + ['NDAQ']*30,\n",
    "    ...     'Close': [150 + i*0.5 for i in range(30)] + [100 + i*0.3 for i in range(30)]\n",
    "    ... })\n",
    "    >>> df_with_rs = calculate_relative_strength(df, benchmark_ticker='NDAQ', lookback_period=7)\n",
    "    >>> # RS on day 10 uses data from day 10 and day 3 only (7 days back)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a copy\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure date column is datetime and sort chronologically\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df = df.sort_values([ticker_col, date_col]).reset_index(drop=True)\n",
    "    \n",
    "    # Get unique dates in chronological order\n",
    "    all_dates = sorted(df[date_col].unique())\n",
    "    \n",
    "    # Extract benchmark data and create lookup dictionary\n",
    "    benchmark_df = df[df[ticker_col] == benchmark_ticker][[date_col, close_col]].copy()\n",
    "    \n",
    "    # Check if benchmark exists\n",
    "    if len(benchmark_df) == 0:\n",
    "        raise ValueError(f\"Benchmark ticker '{benchmark_ticker}' not found in dataframe\")\n",
    "    \n",
    "    # Create benchmark price lookup by date\n",
    "    benchmark_prices = dict(zip(benchmark_df[date_col], benchmark_df[close_col]))\n",
    "    \n",
    "    # Calculate RS for each ticker separately\n",
    "    def calc_rs_for_ticker(ticker_df):\n",
    "        \"\"\"Calculate RS for a single ticker using only historical data\"\"\"\n",
    "        ticker_name = ticker_df[ticker_col].iloc[0]\n",
    "        \n",
    "        # Skip benchmark ticker itself\n",
    "        if ticker_name == benchmark_ticker:\n",
    "            ticker_df['RS_%'] = 0.0\n",
    "            return ticker_df\n",
    "        \n",
    "        # Reset index for positional access\n",
    "        ticker_df = ticker_df.reset_index(drop=True)\n",
    "        \n",
    "        rs_values = []\n",
    "        \n",
    "        for idx in range(len(ticker_df)):\n",
    "            current_date = ticker_df[date_col].iloc[idx]\n",
    "            current_price = ticker_df[close_col].iloc[idx]\n",
    "            \n",
    "            # Get current benchmark price for this date\n",
    "            current_bench_price = benchmark_prices.get(current_date)\n",
    "            \n",
    "            if current_bench_price is None or current_bench_price == 0:\n",
    "                rs_values.append(0.0)\n",
    "                continue\n",
    "            \n",
    "            # Find historical date (lookback periods ago)\n",
    "            # Must use only data from EARLIER dates\n",
    "            if idx < lookback_period:\n",
    "                # Not enough historical data available\n",
    "                rs_values.append(0.0)\n",
    "                continue\n",
    "            \n",
    "            # Get historical prices from lookback_period bars ago\n",
    "            historical_idx = idx - lookback_period\n",
    "            historical_date = ticker_df[date_col].iloc[historical_idx]\n",
    "            historical_price = ticker_df[close_col].iloc[historical_idx]\n",
    "            \n",
    "            # Get historical benchmark price\n",
    "            historical_bench_price = benchmark_prices.get(historical_date)\n",
    "            \n",
    "            if historical_bench_price is None or historical_bench_price == 0:\n",
    "                rs_values.append(0.0)\n",
    "                continue\n",
    "            \n",
    "            # Calculate ratios using ONLY historical data\n",
    "            current_ratio = current_price / current_bench_price\n",
    "            historical_ratio = historical_price / historical_bench_price\n",
    "            \n",
    "            # Calculate RS\n",
    "            if historical_ratio > 0:\n",
    "                rs = ((current_ratio - historical_ratio) / historical_ratio) * 100\n",
    "            else:\n",
    "                rs = 0.0\n",
    "            \n",
    "            rs_values.append(rs)\n",
    "        \n",
    "        ticker_df['RS_%'] = rs_values\n",
    "        \n",
    "        return ticker_df\n",
    "    \n",
    "    # Apply to each ticker\n",
    "    df = df.groupby(ticker_col, group_keys=False).apply(calc_rs_for_ticker)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8283ce48-c2de-4ded-8480-461e1ef8f62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(df, benchmark_ticker = \"NDAQ\", \n",
    "                    coin_strength_threshold=-5.0,\n",
    "                    bench_weakness_threshold=-10.0,\n",
    "                    rs_threshold=5.0,\n",
    "                    date_col='Date', ticker_col='Ticker'):\n",
    "    \"\"\"\n",
    "    Detect outlier tickers: strong performance during benchmark weakness.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with columns: Date, Ticker, Drawdown_%, RS_%\n",
    "        (Must have already run calculate_drawdowns and calculate_relative_strength)\n",
    "    benchmark_ticker : str\n",
    "        Ticker symbol used as benchmark\n",
    "    coin_strength_threshold : float, default=-5.0\n",
    "        Ticker drawdown must be > this value (closer to peak)\n",
    "        Example: -5.0 means ticker must be within 5% of its peak\n",
    "    bench_weakness_threshold : float, default=-10.0\n",
    "        Benchmark drawdown must be < this value (significant weakness)\n",
    "        Example: -10.0 means benchmark must be down >10% from peak\n",
    "    rs_threshold : float, default=5.0\n",
    "        Ticker RS must be > this value (outperforming benchmark)\n",
    "        Example: 5.0 means ticker must be +5% stronger than benchmark\n",
    "    date_col : str, default='Date'\n",
    "        Name of the date column\n",
    "    ticker_col : str, default='Ticker'\n",
    "        Name of the ticker column\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Original dataframe with added 'Outlier' boolean column\n",
    "    \n",
    "    Outlier Criteria (ALL must be true):\n",
    "    ------------------------------------\n",
    "    1. Ticker Strength: Drawdown_% > coin_strength_threshold\n",
    "       → Ticker is near its recent peak (small drawdown)\n",
    "    \n",
    "    2. Benchmark Weakness: Benchmark Drawdown_% < bench_weakness_threshold\n",
    "       → Market/Benchmark is in significant drawdown\n",
    "    \n",
    "    3. Relative Strength: RS_% > rs_threshold\n",
    "       → Ticker is outperforming benchmark significantly\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> # Assuming df already has Drawdown_% and RS_% columns\n",
    "    >>> df_outliers = detect_outliers(df, benchmark_ticker='NDAQ',\n",
    "    ...                               coin_strength_threshold=-5.0,\n",
    "    ...                               bench_weakness_threshold=-10.0,\n",
    "    ...                               rs_threshold=5.0)\n",
    "    >>> print(df_outliers[df_outliers['Outlier']==True][['Date', 'Ticker', 'Drawdown_%', 'RS_%']])\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a copy\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure date column is datetime\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    \n",
    "    # Check required columns exist\n",
    "    required_cols = ['Drawdown_%', 'RS_%']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}. \"\n",
    "                        f\"Run calculate_drawdowns() and calculate_relative_strength() first.\")\n",
    "    \n",
    "    # Get benchmark drawdown for each date\n",
    "    benchmark_df = df[df[ticker_col] == benchmark_ticker][[date_col, 'Drawdown_%']].copy()\n",
    "    benchmark_df = benchmark_df.rename(columns={'Drawdown_%': 'Benchmark_DD_%'})\n",
    "    \n",
    "    # Check if benchmark exists\n",
    "    if len(benchmark_df) == 0:\n",
    "        raise ValueError(f\"Benchmark ticker '{benchmark_ticker}' not found in dataframe\")\n",
    "    \n",
    "    # Merge benchmark drawdown\n",
    "    df = df.merge(benchmark_df, on=date_col, how='left')\n",
    "    \n",
    "    # Detect outliers\n",
    "    def is_outlier_row(row):\n",
    "        \"\"\"Check if a single row meets outlier criteria\"\"\"\n",
    "        # Skip benchmark ticker\n",
    "        if row[ticker_col] == benchmark_ticker:\n",
    "            return False\n",
    "        \n",
    "        # Criterion 1: Ticker is strong (near peak)\n",
    "        coin_strong = row['Drawdown_%'] > coin_strength_threshold\n",
    "        \n",
    "        # Criterion 2: Benchmark is weak (significant drawdown)\n",
    "        bench_weak = row['Benchmark_DD_%'] < bench_weakness_threshold\n",
    "        \n",
    "        # Criterion 3: Ticker has strong RS (outperforming)\n",
    "        rs_strong = row['RS_%'] > rs_threshold\n",
    "        \n",
    "        # All criteria must be true\n",
    "        return coin_strong and bench_weak and rs_strong\n",
    "    \n",
    "    # Apply outlier detection\n",
    "    df['Outlier'] = df.apply(is_outlier_row, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3b80528-05c0-4dae-a0f2-5c9e47666137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_62652/4010749748.py:46: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(ticker_col, as_index=False, group_keys=False).apply(calc_aroon)\n"
     ]
    }
   ],
   "source": [
    "# Calculate all indicators using groupby\n",
    "grouped = data.groupby('Ticker')\n",
    "\n",
    "# RSI and change\n",
    "data['RSI'] = grouped['Close'].transform(lambda x: calculate_rsi(x))\n",
    "data['RSI_Chg'] = grouped['RSI'].diff()\n",
    "data['RSI_Divergence'] = grouped.apply(\n",
    "    lambda x: rsi_divergence(x, lookback=14), include_groups=False\n",
    ").reset_index(level=0, drop=True)\n",
    "\n",
    "# MACD\n",
    "data['EMA_12'] = grouped['Close'].transform(lambda x: x.ewm(span=12, adjust=False).mean())\n",
    "data['EMA_26'] = grouped['Close'].transform(lambda x: x.ewm(span=26, adjust=False).mean())\n",
    "data['MACD'] = data['EMA_12'] - data['EMA_26']\n",
    "data['MACD_Signal'] = grouped['MACD'].transform(lambda x: x.ewm(span=9, adjust=False).mean())\n",
    "data['MACD_Histogram'] = data['MACD'] - data['MACD_Signal']\n",
    "data = data.drop(['EMA_12', 'EMA_26'], axis=1)  # Clean up intermediate columns\n",
    "\n",
    "# Rate of Change (10-day)\n",
    "data['ROC'] = grouped['Close'].transform(lambda x: x.pct_change(periods=10) * 100)\n",
    "\n",
    "# Simple Moving Averages by X days\n",
    "for days in [10, 20, 50, 100, 150, 200, 250]:\n",
    "    data[f'SMA_{days}'] = grouped['Close'].transform(lambda x: x.rolling(window=days).mean())\n",
    "\n",
    "# Awesome Oscillator\n",
    "data['SMA_5'] = grouped['Close'].transform(lambda x: x.rolling(window=5).mean())\n",
    "data['SMA_34'] = grouped['Close'].transform(lambda x: x.rolling(window=34).mean())\n",
    "data['AO'] = data['SMA_5'] - data['SMA_34']\n",
    "data['AO_Chg'] = data.groupby('Ticker')['AO'].diff()\n",
    "data = data.drop(['SMA_5', 'SMA_34'], axis=1)  # Clean up intermediate columns\n",
    "\n",
    "# Close X days ago\n",
    "for days in [1, 2, 3, 4, 5]:\n",
    "    data[f'Close_{days}days_ago'] = grouped['Close'].shift(days)\n",
    "\n",
    "# Close change since yesterday\n",
    "data['Close_Chg'] = grouped['Close'].diff()\n",
    "data['Close_ChgPct'] = grouped['Close'].transform(lambda x: x.pct_change() * 100)\n",
    "\n",
    "# Volume X days ago\n",
    "for days in [1]:\n",
    "    data[f'Volume_{days}d_ago'] = grouped['Volume'].shift(days)\n",
    "\n",
    "# Volume change since yesterday\n",
    "data['Volume_Chg'] = grouped['Volume'].diff()\n",
    "data['Volume_ChgPct'] = grouped['Volume'].transform(lambda x: x.pct_change() * 100)\n",
    "\n",
    "# Aroon Up and Down\n",
    "data = add_aroon(data, period=14, ticker_col='Ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31c75366-f3fe-4ec8-b4a0-f124762ba265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_62652/34316304.py:76: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(ticker_col, group_keys=False).apply(calc_dd_for_ticker)\n",
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_62652/548207248.py:141: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(ticker_col, group_keys=False).apply(calc_rs_for_ticker)\n"
     ]
    }
   ],
   "source": [
    "date_col = 'Date'\n",
    "ticker_col = 'Ticker'\n",
    "close_col = 'Close'\n",
    "\n",
    "# Drawdowns\n",
    "data = calculate_drawdowns(data, lookback_period=100, date_col=date_col, ticker_col=ticker_col, close_col=close_col)\n",
    "\n",
    "# Relative Strength\n",
    "data = calculate_relative_strength(data, benchmark_ticker = \"NDAQ\", lookback_period=7, \n",
    "                                date_col=date_col, ticker_col=ticker_col, close_col=close_col)\n",
    "\n",
    "# Outliers\n",
    "data = detect_outliers(data, benchmark_ticker = \"NDAQ\", \n",
    "                    coin_strength_threshold=-5.0,\n",
    "                    bench_weakness_threshold=-10.0,\n",
    "                    rs_threshold=5.0,\n",
    "                    date_col=date_col, ticker_col='Ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26514e66-e3d1-47ae-b9c1-4f3ed4c96928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data with indicators:\n",
      "         Date Ticker       Close        RSI      MACD      SMA_20  \\\n",
      "30 2022-12-13   AAPL  143.446945  42.356382 -1.263582  144.610534   \n",
      "31 2022-12-14   AAPL  141.218384  37.787432 -1.297656  144.273784   \n",
      "32 2022-12-15   AAPL  134.601685  33.843577 -1.837392  143.667830   \n",
      "33 2022-12-16   AAPL  132.639343  35.733140 -2.395863  142.868599   \n",
      "34 2022-12-19   AAPL  130.529129  36.715034 -2.974444  141.935756   \n",
      "35 2022-12-20   AAPL  130.460129  20.129035 -3.399356  141.161181   \n",
      "36 2022-12-21   AAPL  133.566284  27.979341 -3.445741  140.434923   \n",
      "37 2022-12-22   AAPL  130.391068  25.595124 -3.696108  139.506022   \n",
      "38 2022-12-23   AAPL  130.026184  26.261500 -3.879252  138.704819   \n",
      "39 2022-12-27   AAPL  128.221680  27.960212 -4.122481  138.005186   \n",
      "\n",
      "    Close_ChgPct  Volume_ChgPct  \n",
      "30      0.678247      33.242411  \n",
      "31     -1.553579     -12.350058  \n",
      "32     -4.685438      20.221725  \n",
      "33     -1.457888      61.886004  \n",
      "34     -1.590941     -50.303359  \n",
      "35     -0.052862      -2.713569  \n",
      "36      2.380923      10.971061  \n",
      "37     -2.377259      -9.398450  \n",
      "38     -0.279838     -18.030599  \n",
      "39     -1.387801       8.137441  \n",
      "\n",
      "\n",
      "All columns:\n",
      "['Date', 'Ticker', 'Close', 'High', 'Low', 'Open', 'Volume', 'RSI', 'RSI_Chg', 'RSI_Divergence', 'MACD', 'MACD_Signal', 'MACD_Histogram', 'ROC', 'SMA_10', 'SMA_20', 'SMA_50', 'SMA_100', 'SMA_150', 'SMA_200', 'SMA_250', 'AO', 'AO_Chg', 'Close_1days_ago', 'Close_2days_ago', 'Close_3days_ago', 'Close_4days_ago', 'Close_5days_ago', 'Close_Chg', 'Close_ChgPct', 'Volume_1d_ago', 'Volume_Chg', 'Volume_ChgPct', 'Aroon_Up', 'Aroon_Down', 'Drawdown_%', 'RS_%', 'Benchmark_DD_%', 'Outlier']\n"
     ]
    }
   ],
   "source": [
    "# Display sample\n",
    "print(\"Sample data with indicators:\")\n",
    "print(data[data['Ticker'] == 'AAPL'].iloc[30:40][\n",
    "    ['Date', 'Ticker', 'Close', 'RSI', 'MACD', 'SMA_20', 'Close_ChgPct', 'Volume_ChgPct']\n",
    "])\n",
    "\n",
    "print(\"\\n\\nAll columns:\")\n",
    "print(data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6702594a-bf5f-49c2-b188-50b4ed4c84b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from last day\n",
    "lastday = data.loc[data.groupby('Ticker')['Date'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fd5aa20-bc14-40c7-9951-b42d8e986f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saved to TADASI_yhfinance.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Save\n",
    "excel_file = 'TADASI_yhfinance.xlsx'\n",
    "with pd.ExcelWriter(excel_file, engine='xlsxwriter') as writer:\n",
    "    ndaq100df.to_excel(writer, sheet_name='Tickers', index=False)\n",
    "    data.to_excel(writer, sheet_name='OHLC', index=False)\n",
    "    lastday.to_excel(writer, sheet_name='Last_Day', index=False)\n",
    "print(f\"\\n Saved to {excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "306dbd29-583d-46c1-8588-fa51f5f0927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ranaroussi/yfinance/issues/2469\n",
    "# import curl_cffi\n",
    "# session = curl_cffi.Session(impersonate=\"chrome\", timeout=5)\n",
    "# ticker = yf.Ticker('GBPEUR=X', session=session)\n",
    "# data = ticker.history(start='2025-05-05', end='2025-05-07')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722fde7b-bdc7-42f0-af82-0fb30cbd3ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
