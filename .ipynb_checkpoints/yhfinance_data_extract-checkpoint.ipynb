{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "386d0bca-7073-432f-a327-34bf23dd0ba1",
   "metadata": {},
   "source": [
    "# Data Extraction from `yhfinance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb6c7eb7-5551-465d-8d20-76737438f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b345220-9770-499b-9fe4-eba0972f8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4c5bb2c-5359-4924-9c0d-b03ec19f5170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SAndP500_Wikipedia_Scrape():\n",
    "    \"\"\"\n",
    "    Fetch S&P500 tickers and corresponding data from Wikipedia\n",
    "    \"\"\"\n",
    "    print(\"Fetching from Wikipedia...\")\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    # Download HTML, parse it to find all tables and create corresponding pandas DataFrames and return list of DataFrames\n",
    "    response = requests.get(url, headers=headers)\n",
    "    tables = pd.read_html(StringIO(response.text))\n",
    "    sp500_table = tables[0]\n",
    "    \n",
    "    # Create DataFrame with relevant info\n",
    "    df = pd.DataFrame({\n",
    "        'Ticker': sp500_table['Symbol'].tolist(),\n",
    "        'Company': sp500_table['Security'].tolist(),\n",
    "        'Sector': sp500_table['GICS Sector'].tolist(),\n",
    "        'Industry': sp500_table['GICS Sub-Industry'].tolist()\n",
    "    })\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f443982b-1634-4f03-85dc-1552e3704214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NASDAQ100_Wikipedia_Scrape():\n",
    "    \"\"\"\n",
    "    Fetch NASDAQ100 tickers and corresponding data from Wikipedia\n",
    "    \"\"\"\n",
    "    print(\"Fetching from Wikipedia...\")\n",
    "    url = 'https://en.wikipedia.org/wiki/Nasdaq-100'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    # Download HTML, parse it to find all tables and create corresponding pandas DataFrames and return list of DataFrames\n",
    "    response = requests.get(url, headers=headers)\n",
    "    tables = pd.read_html(StringIO(response.text))\n",
    "\n",
    "    # Find NASDAQ table\n",
    "    for index, table in enumerate(tables):\n",
    "        if 'Ticker' in table.columns and len(table) > 90:\n",
    "            ndaq100_table = tables[index]\n",
    "    \n",
    "    # Create DataFrame with relevant info\n",
    "    df = pd.DataFrame({\n",
    "        'Ticker': ndaq100_table['Ticker'].tolist(),\n",
    "        'Company': ndaq100_table['Company'].tolist(),\n",
    "        'Industry': ndaq100_table['ICB Industry'].tolist(),\n",
    "        'Sector': ndaq100_table['ICB Subsector'].tolist(),\n",
    "    })\n",
    "\n",
    "    # Add NDAQ manually\n",
    "    ndaq_row = pd.DataFrame({\n",
    "        'Ticker': [\"NDAQ\"],\n",
    "        'Company': [\"Nasdaq, Inc.\"],\n",
    "        'Industry': [\"Stock Exchange\"],\n",
    "        'Sector': [\"Financial Services\"],\n",
    "    })\n",
    "\n",
    "    df = pd.concat([df, ndaq_row], ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b9bfbfa-2221-4511-81be-6586db97ce5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching from Wikipedia...\n",
      " Successfully fetched 103 NASDAQ-100 tickers!\n",
      "\n",
      "============================================================\n",
      "Total tickers: 103\n",
      "\n",
      "First 10 tickers:\n",
      "Ticker                 Company               Industry                          Sector\n",
      "  ADBE              Adobe Inc.             Technology               Computer Software\n",
      "   AMD  Advanced Micro Devices             Technology                  Semiconductors\n",
      "  ABNB                  Airbnb Consumer Discretionary Diversified Commercial Services\n",
      " GOOGL Alphabet Inc. (Class A)             Technology               Computer Software\n",
      "  GOOG Alphabet Inc. (Class C)             Technology               Computer Software\n",
      "  AMZN                  Amazon Consumer Discretionary  Catalog/Specialty Distribution\n",
      "   AEP American Electric Power              Utilities              Electric Utilities\n",
      "  AMGN                   Amgen            Health Care                   Biotechnology\n",
      "   ADI          Analog Devices             Technology                  Semiconductors\n",
      "  AAPL              Apple Inc.             Technology          Computer Manufacturing\n",
      "\n",
      "============================================================\n",
      "Sector Distribution:\n",
      "============================================================\n",
      "Sector\n",
      "Computer Software                                18\n",
      "Semiconductors                                   15\n",
      "Biotechnology                                     7\n",
      "Diversified Commercial Services                   5\n",
      "EDP Services                                      5\n",
      "Beverages                                         4\n",
      "Miscellaneous Amusement & Recreation Services     3\n",
      "Retail                                            2\n",
      "Packaged Foods                                    2\n",
      "Computer Peripheral Equipment                     2\n",
      "Cable & Other Pay Television Services             2\n",
      "Power Generation                                  2\n",
      "Electric Utilities                                2\n",
      "Industrial Machinery                              2\n",
      "Transportation Services                           1\n",
      "Catalog/Specialty Distribution                    1\n",
      "Apparel                                           1\n",
      "Hotels/Resorts                                    1\n",
      "Specialty Retailers                               1\n",
      "Consumer Electronics                              1\n",
      "Auto & Home Supply Stores                         1\n",
      "Trucking Freight/Courier Services                 1\n",
      "Motor Vehicles                                    1\n",
      "Broadcasting & Communications Equipment           1\n",
      "Clothing/Shoe/Accessory Stores                    1\n",
      "Restaurants                                       1\n",
      "Telecommunications Services                       1\n",
      "Automobiles                                       1\n",
      "Publishing                                        1\n",
      "Major Chemicals                                   1\n",
      "Electronic Components                             1\n",
      "Garments & Clothing                               1\n",
      "Industrial Specialties                            1\n",
      "Aerospace                                         1\n",
      "Medical Electronics                               1\n",
      "Retail Building Materials                         1\n",
      "Computer Manufacturing                            1\n",
      "Oil & Gas Production                              1\n",
      "Medical/Dental Instruments                        1\n",
      "Railroads                                         1\n",
      "Department/Specialty Retail Stores                1\n",
      "Real Estate                                       1\n",
      "Ordnance & Accessories                            1\n",
      "Oil Equipment and Services                        1\n",
      "Computer Communications Equipment                 1\n",
      "Financial Services                                1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ndaq100df = NASDAQ100_Wikipedia_Scrape()\n",
    "    ticker_list = ndaq100df['Ticker'].tolist()\n",
    "    print(f\" Successfully fetched {len(ndaq100df)} NASDAQ-100 tickers!\")\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Total tickers: {len(ndaq100df)}\")\n",
    "    print(\"\\nFirst 10 tickers:\")\n",
    "    print(ndaq100df.head(10).to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Sector Distribution:\")\n",
    "    print(\"=\"*60)\n",
    "    print(ndaq100df['Sector'].value_counts())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Python scrape failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6503afcd-f74d-4195-85f9-f49f5bca2a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker_list = [\"AAPL\", \"META\", \"NDAQ\", \"SPY\",]\n",
    "# company_list = []\n",
    "\n",
    "# for ticker_symbol in ticker_list:\n",
    "#     try: \n",
    "#         stock = yf.Ticker(ticker_symbol)\n",
    "#         company_name = stock.info.get('longName', 'N/A')\n",
    "#         company_list.append(company_name)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching {ticker}: {e}\")\n",
    "#         company_list.append(\"Error\")\n",
    "\n",
    "# tick_comp_df = pd.DataFrame({\n",
    "#     'Ticker': ticker_list,\n",
    "#     'Company': company_list\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26536684-ed5b-4b0b-b71b-ee5c2a7157b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_80324/2776169727.py:3: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker_list, start=start_date, end=end_date, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date Ticker       Close        High         Low        Open  \\\n",
      "0 2022-10-31   AAPL  150.957092  151.843115  149.559161  150.779897   \n",
      "1 2022-10-31   ABNB  106.910004  113.800003  106.669998  113.059998   \n",
      "2 2022-10-31   ADBE  318.500000  325.579987  317.420013  323.489990   \n",
      "3 2022-10-31    ADI  135.263535  136.458552  133.347738  136.392156   \n",
      "4 2022-10-31    ADP  226.601654  227.248554  224.501590  225.560992   \n",
      "5 2022-10-31   ADSK  214.300003  216.289993  214.000000  214.759995   \n",
      "6 2022-10-31    AEP   78.322495   79.632028   77.823627   79.596393   \n",
      "7 2022-10-31   AMAT   85.900398   86.980356   85.287452   86.454971   \n",
      "8 2022-10-31    AMD   60.060001   61.860001   59.529999   60.750000   \n",
      "9 2022-10-31   AMGN  245.694214  247.021055  243.558527  244.649099   \n",
      "\n",
      "       Volume  \n",
      "0  97943200.0  \n",
      "1  10733800.0  \n",
      "2   3253200.0  \n",
      "3   3078300.0  \n",
      "4   1711400.0  \n",
      "5    965000.0  \n",
      "6   4104000.0  \n",
      "7   6875400.0  \n",
      "8  73274100.0  \n",
      "9   3033600.0  \n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.datetime(2022, 10, 29)\n",
    "end_date = datetime.datetime(2025, 10, 29)\n",
    "data = yf.download(ticker_list, start=start_date, end=end_date, progress=False)\n",
    "data = data.stack(level='Ticker', future_stack=True).reset_index()\n",
    "data.columns.name = None\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d149d89-3bda-4cdd-8d03-9a6d123d4d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate RSI\n",
    "def calculate_rsi(series, window=14):\n",
    "    delta = series.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "# Function to calculate Aroon\n",
    "def add_aroon(data, period=14, ticker_col=None):\n",
    "    \"\"\"\n",
    "    Add Aroon Up and Aroon Down indicators to data\n",
    "    \n",
    "    Parameters:\n",
    "        data (DataFrame): Must have 'High' and 'Low' columns\n",
    "        period (int): Lookback period (default: 14)\n",
    "        ticker_col (str): Column name for ticker if multi-ticker data\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Data with 'Aroon_Up' and 'Aroon_Down' columns added\n",
    "        \n",
    "    Note: Intermediate columns are automatically removed\n",
    "    \"\"\"\n",
    "    \n",
    "    df = data.copy()\n",
    "    \n",
    "    def calc_aroon(group):\n",
    "        # Periods since highest high\n",
    "        periods_high = group['High'].rolling(window=period).apply(\n",
    "            lambda x: period - 1 - np.argmax(x), raw=True\n",
    "        )\n",
    "        \n",
    "        # Periods since lowest low  \n",
    "        periods_low = group['Low'].rolling(window=period).apply(\n",
    "            lambda x: period - 1 - np.argmin(x), raw=True\n",
    "        )\n",
    "        \n",
    "        # Calculate Aroon indicators\n",
    "        group['Aroon_Up'] = ((period - periods_high) / period)\n",
    "        group['Aroon_Down'] = ((period - periods_low) / period)\n",
    "        \n",
    "        return group\n",
    "    \n",
    "    # Apply to each ticker or entire dataset\n",
    "    if ticker_col and ticker_col in df.columns:\n",
    "        df = df.groupby(ticker_col, as_index=False, group_keys=False).apply(calc_aroon)\n",
    "    else:\n",
    "        df = calc_aroon(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca4c5bd8-9257-40e9-abc7-77184fdb57e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect RSI divergence\n",
    "def rsi_divergence(group, lookback=14):\n",
    "    \"\"\"\n",
    "    Detect RSI divergence for each row in a group\n",
    "    Returns Series with divergence directions (1, -1, or 0)\n",
    "    \"\"\"\n",
    "    result = pd.Series(index=group.index, dtype=object)\n",
    "    \n",
    "    for i in range(len(group)):\n",
    "        # Need at least lookback periods\n",
    "        if i < lookback:\n",
    "            result.iloc[i] = None\n",
    "            continue\n",
    "        \n",
    "        # Get the lookback window (including current point)\n",
    "        start_idx = max(0, i - lookback)\n",
    "        price_window = group['Close'].iloc[start_idx:i+1]\n",
    "        rsi_window = group['RSI'].iloc[start_idx:i+1]\n",
    "        \n",
    "        # Current values\n",
    "        current_price = group['Close'].iloc[i]\n",
    "        current_rsi = group['RSI'].iloc[i]\n",
    "        \n",
    "        # Skip if RSI is NaN\n",
    "        if pd.isna(current_rsi):\n",
    "            result.iloc[i] = None\n",
    "            continue\n",
    "        \n",
    "        # Find min and max in the window (excluding current point)\n",
    "        price_window_prev = price_window.iloc[:-1]\n",
    "        rsi_window_prev = rsi_window.iloc[:-1]\n",
    "        \n",
    "        if len(price_window_prev) == 0:\n",
    "            result.iloc[i] = None\n",
    "            continue\n",
    "        \n",
    "        # Get indices of min/max\n",
    "        price_min_idx = price_window_prev.idxmin()\n",
    "        price_max_idx = price_window_prev.idxmax()\n",
    "        \n",
    "        # Bullish Divergence: Price making lower lows, RSI making higher lows\n",
    "        if price_min_idx != group.index[i]:  # Min is not at current point\n",
    "            prev_price_low = price_window_prev.loc[price_min_idx]\n",
    "            prev_rsi_at_price_low = group.loc[price_min_idx, 'RSI']\n",
    "            \n",
    "            if pd.notna(prev_rsi_at_price_low) and current_price < prev_price_low and current_rsi > prev_rsi_at_price_low:\n",
    "                result.iloc[i] = 1\n",
    "                continue\n",
    "        \n",
    "        # Bearish Divergence: Price making higher highs, RSI making lower highs\n",
    "        if price_max_idx != group.index[i]:  # Max is not at current point\n",
    "            prev_price_high = price_window_prev.loc[price_max_idx]\n",
    "            prev_rsi_at_price_high = group.loc[price_max_idx, 'RSI']\n",
    "            \n",
    "            if pd.notna(prev_rsi_at_price_high) and current_price > prev_price_high and current_rsi < prev_rsi_at_price_high:\n",
    "                result.iloc[i] = -1\n",
    "                continue\n",
    "        \n",
    "        result.iloc[i] = 0\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1e43497-bab8-4bae-8ff0-fcba76fa1b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_drawdowns(df, lookback_period=100, date_col='Date', ticker_col='Ticker', close_col='Close'):\n",
    "    \"\"\"\n",
    "    Calculate rolling drawdown from peak for each ticker at each date.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with columns: Date, Ticker, Open, High, Low, Close\n",
    "    lookback_period : int, default=100\n",
    "        Number of periods to look back for peak calculation\n",
    "    date_col : str, default='Date'\n",
    "        Name of the date column\n",
    "    ticker_col : str, default='Ticker'\n",
    "        Name of the ticker column\n",
    "    close_col : str, default='Close'\n",
    "        Name of the close price column\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Original dataframe with added 'Drawdown_%' column\n",
    "    \n",
    "    Formula:\n",
    "    --------\n",
    "    Drawdown = ((Current Price - Peak Price in Window) / Peak Price) × 100\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> df = pd.DataFrame({\n",
    "    ...     'Date': pd.date_range('2024-01-01', periods=150, freq='D'),\n",
    "    ...     'Ticker': ['AAPL']*150,\n",
    "    ...     'Close': np.random.randn(150).cumsum() + 100\n",
    "    ... })\n",
    "    >>> df_with_dd = calculate_drawdowns(df, lookback_period=50)\n",
    "    >>> print(df_with_dd[['Date', 'Ticker', 'Close', 'Drawdown_%']].tail())\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a copy to avoid modifying original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure date column is datetime\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    \n",
    "    # Sort by ticker and date\n",
    "    df = df.sort_values([ticker_col, date_col]).reset_index(drop=True)\n",
    "    \n",
    "    # Calculate drawdown for each ticker separately\n",
    "    def calc_dd_for_ticker(ticker_df):\n",
    "        \"\"\"Calculate drawdown for a single ticker\"\"\"\n",
    "        # Get closing prices\n",
    "        prices = ticker_df[close_col].values\n",
    "        \n",
    "        # Calculate rolling maximum (peak) within lookback window\n",
    "        drawdowns = []\n",
    "        for i in range(len(prices)):\n",
    "            # Determine lookback window\n",
    "            start_idx = max(0, i - lookback_period + 1)\n",
    "            window_prices = prices[start_idx:i+1]\n",
    "            \n",
    "            # Find peak in window\n",
    "            peak = np.max(window_prices)\n",
    "            \n",
    "            # Calculate drawdown\n",
    "            current_price = prices[i]\n",
    "            if peak > 0:\n",
    "                dd = ((current_price - peak) / peak)\n",
    "            else:\n",
    "                dd = 0.0\n",
    "            \n",
    "            drawdowns.append(dd)\n",
    "        \n",
    "        ticker_df['Drawdown_%'] = drawdowns\n",
    "        return ticker_df\n",
    "    \n",
    "    # Apply to each ticker\n",
    "    df = df.groupby(ticker_col, group_keys=False).apply(calc_dd_for_ticker)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cae7e6e9-ca51-476b-8e57-ad41d8fb8b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_strength(df, benchmark_ticker, lookback_period=7, \n",
    "                                date_col='Date', ticker_col='Ticker', close_col='Close'):\n",
    "    \"\"\"\n",
    "    Calculate Relative Strength of each ticker vs benchmark using ONLY historical data.\n",
    "    \n",
    "    CRITICAL: For each date, only uses data from EARLIER dates (no look-ahead bias).\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with columns: Date, Ticker, Open, High, Low, Close\n",
    "    benchmark_ticker : str\n",
    "        Ticker symbol to use as benchmark (e.g., 'NDAQ', 'SPY')\n",
    "    lookback_period : int, default=7\n",
    "        Number of HISTORICAL periods to calculate RS over\n",
    "    date_col : str, default='Date'\n",
    "        Name of the date column\n",
    "    ticker_col : str, default='Ticker'\n",
    "        Name of the ticker column\n",
    "    close_col : str, default='Close'\n",
    "        Name of the close price column\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Original dataframe with added 'RS_%' column\n",
    "    \n",
    "    Temporal Logic:\n",
    "    ---------------\n",
    "    For date T, RS calculation uses:\n",
    "    - Current ratio: Asset[T] / Benchmark[T]\n",
    "    - Historical ratio: Asset[T-lookback] / Benchmark[T-lookback]\n",
    "    - Both Asset and Benchmark data must exist for dates T and T-lookback\n",
    "    \n",
    "    Formula:\n",
    "    --------\n",
    "    RS_T = ((Ratio_T - Ratio_(T-lookback)) / Ratio_(T-lookback)) × 100\n",
    "    where Ratio_T = Asset_Price_T / Benchmark_Price_T\n",
    "    \n",
    "    Example Timeline:\n",
    "    -----------------\n",
    "    Date          Asset    Benchmark   Ratio    RS (7-day)\n",
    "    2024-01-01    150      100         1.50     N/A (need 7 days history)\n",
    "    2024-01-02    152      101         1.505    N/A\n",
    "    ...\n",
    "    2024-01-08    160      105         1.524    RS = ((1.524-1.50)/1.50)*100 = +1.6%\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> df = pd.DataFrame({\n",
    "    ...     'Date': pd.date_range('2024-01-01', periods=30, freq='D').tolist() * 2,\n",
    "    ...     'Ticker': ['AAPL']*30 + ['NDAQ']*30,\n",
    "    ...     'Close': [150 + i*0.5 for i in range(30)] + [100 + i*0.3 for i in range(30)]\n",
    "    ... })\n",
    "    >>> df_with_rs = calculate_relative_strength(df, benchmark_ticker='NDAQ', lookback_period=7)\n",
    "    >>> # RS on day 10 uses data from day 10 and day 3 only (7 days back)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a copy\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure date column is datetime and sort chronologically\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df = df.sort_values([ticker_col, date_col]).reset_index(drop=True)\n",
    "    \n",
    "    # Get unique dates in chronological order\n",
    "    all_dates = sorted(df[date_col].unique())\n",
    "    \n",
    "    # Extract benchmark data and create lookup dictionary\n",
    "    benchmark_df = df[df[ticker_col] == benchmark_ticker][[date_col, close_col]].copy()\n",
    "    \n",
    "    # Check if benchmark exists\n",
    "    if len(benchmark_df) == 0:\n",
    "        raise ValueError(f\"Benchmark ticker '{benchmark_ticker}' not found in dataframe\")\n",
    "    \n",
    "    # Create benchmark price lookup by date\n",
    "    benchmark_prices = dict(zip(benchmark_df[date_col], benchmark_df[close_col]))\n",
    "    \n",
    "    # Calculate RS for each ticker separately\n",
    "    def calc_rs_for_ticker(ticker_df):\n",
    "        \"\"\"Calculate RS for a single ticker using only historical data\"\"\"\n",
    "        ticker_name = ticker_df[ticker_col].iloc[0]\n",
    "        \n",
    "        # Skip benchmark ticker itself\n",
    "        if ticker_name == benchmark_ticker:\n",
    "            ticker_df['RS_%'] = 0.0\n",
    "            return ticker_df\n",
    "        \n",
    "        # Reset index for positional access\n",
    "        ticker_df = ticker_df.reset_index(drop=True)\n",
    "        \n",
    "        rs_values = []\n",
    "        \n",
    "        for idx in range(len(ticker_df)):\n",
    "            current_date = ticker_df[date_col].iloc[idx]\n",
    "            current_price = ticker_df[close_col].iloc[idx]\n",
    "            \n",
    "            # Get current benchmark price for this date\n",
    "            current_bench_price = benchmark_prices.get(current_date)\n",
    "            \n",
    "            if current_bench_price is None or current_bench_price == 0:\n",
    "                rs_values.append(0.0)\n",
    "                continue\n",
    "            \n",
    "            # Find historical date (lookback periods ago)\n",
    "            # Must use only data from EARLIER dates\n",
    "            if idx < lookback_period:\n",
    "                # Not enough historical data available\n",
    "                rs_values.append(0.0)\n",
    "                continue\n",
    "            \n",
    "            # Get historical prices from lookback_period bars ago\n",
    "            historical_idx = idx - lookback_period\n",
    "            historical_date = ticker_df[date_col].iloc[historical_idx]\n",
    "            historical_price = ticker_df[close_col].iloc[historical_idx]\n",
    "            \n",
    "            # Get historical benchmark price\n",
    "            historical_bench_price = benchmark_prices.get(historical_date)\n",
    "            \n",
    "            if historical_bench_price is None or historical_bench_price == 0:\n",
    "                rs_values.append(0.0)\n",
    "                continue\n",
    "            \n",
    "            # Calculate ratios using ONLY historical data\n",
    "            current_ratio = current_price / current_bench_price\n",
    "            historical_ratio = historical_price / historical_bench_price\n",
    "            \n",
    "            # Calculate RS\n",
    "            if historical_ratio > 0:\n",
    "                rs = ((current_ratio - historical_ratio) / historical_ratio)\n",
    "            else:\n",
    "                rs = 0.0\n",
    "            \n",
    "            rs_values.append(rs)\n",
    "        \n",
    "        ticker_df['RS_%'] = rs_values\n",
    "        \n",
    "        return ticker_df\n",
    "    \n",
    "    # Apply to each ticker\n",
    "    df = df.groupby(ticker_col, group_keys=False).apply(calc_rs_for_ticker)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8283ce48-c2de-4ded-8480-461e1ef8f62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers(df, benchmark_ticker = \"NDAQ\", \n",
    "                    coin_strength_threshold=-0.05,\n",
    "                    bench_weakness_threshold=-0.1,\n",
    "                    rs_threshold=0.05,\n",
    "                    date_col='Date', ticker_col='Ticker'):\n",
    "    \"\"\"\n",
    "    Detect outlier tickers: strong performance during benchmark weakness.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with columns: Date, Ticker, Drawdown_%, RS_%\n",
    "        (Must have already run calculate_drawdowns and calculate_relative_strength)\n",
    "    benchmark_ticker : str\n",
    "        Ticker symbol used as benchmark\n",
    "    coin_strength_threshold : float, default=-5.0\n",
    "        Ticker drawdown must be > this value (closer to peak)\n",
    "        Example: -5.0 means ticker must be within 5% of its peak\n",
    "    bench_weakness_threshold : float, default=-10.0\n",
    "        Benchmark drawdown must be < this value (significant weakness)\n",
    "        Example: -10.0 means benchmark must be down >10% from peak\n",
    "    rs_threshold : float, default=5.0\n",
    "        Ticker RS must be > this value (outperforming benchmark)\n",
    "        Example: 5.0 means ticker must be +5% stronger than benchmark\n",
    "    date_col : str, default='Date'\n",
    "        Name of the date column\n",
    "    ticker_col : str, default='Ticker'\n",
    "        Name of the ticker column\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Original dataframe with added 'Outlier' boolean column\n",
    "    \n",
    "    Outlier Criteria (ALL must be true):\n",
    "    ------------------------------------\n",
    "    1. Ticker Strength: Drawdown_% > coin_strength_threshold\n",
    "       → Ticker is near its recent peak (small drawdown)\n",
    "    \n",
    "    2. Benchmark Weakness: Benchmark Drawdown_% < bench_weakness_threshold\n",
    "       → Market/Benchmark is in significant drawdown\n",
    "    \n",
    "    3. Relative Strength: RS_% > rs_threshold\n",
    "       → Ticker is outperforming benchmark significantly\n",
    "    \n",
    "    Example:\n",
    "    --------\n",
    "    >>> # Assuming df already has Drawdown_% and RS_% columns\n",
    "    >>> df_outliers = detect_outliers(df, benchmark_ticker='NDAQ',\n",
    "    ...                               coin_strength_threshold=-5.0,\n",
    "    ...                               bench_weakness_threshold=-10.0,\n",
    "    ...                               rs_threshold=5.0)\n",
    "    >>> print(df_outliers[df_outliers['Outlier']==True][['Date', 'Ticker', 'Drawdown_%', 'RS_%']])\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create a copy\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure date column is datetime\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    \n",
    "    # Check required columns exist\n",
    "    required_cols = ['Drawdown_%', 'RS_%']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing required columns: {missing_cols}. \"\n",
    "                        f\"Run calculate_drawdowns() and calculate_relative_strength() first.\")\n",
    "    \n",
    "    # Get benchmark drawdown for each date\n",
    "    benchmark_df = df[df[ticker_col] == benchmark_ticker][[date_col, 'Drawdown_%']].copy()\n",
    "    benchmark_df = benchmark_df.rename(columns={'Drawdown_%': 'Benchmark_DD_%'})\n",
    "    \n",
    "    # Check if benchmark exists\n",
    "    if len(benchmark_df) == 0:\n",
    "        raise ValueError(f\"Benchmark ticker '{benchmark_ticker}' not found in dataframe\")\n",
    "    \n",
    "    # Merge benchmark drawdown\n",
    "    df = df.merge(benchmark_df, on=date_col, how='left')\n",
    "    \n",
    "    # Detect outliers\n",
    "    def is_outlier_row(row):\n",
    "        \"\"\"Check if a single row meets outlier criteria\"\"\"\n",
    "        # Skip benchmark ticker\n",
    "        if row[ticker_col] == benchmark_ticker:\n",
    "            return False\n",
    "        \n",
    "        # Criterion 1: Ticker is strong (near peak)\n",
    "        coin_strong = row['Drawdown_%'] > coin_strength_threshold\n",
    "        \n",
    "        # Criterion 2: Benchmark is weak (significant drawdown)\n",
    "        bench_weak = row['Benchmark_DD_%'] < bench_weakness_threshold\n",
    "        \n",
    "        # Criterion 3: Ticker has strong RS (outperforming)\n",
    "        rs_strong = row['RS_%'] > rs_threshold\n",
    "        \n",
    "        # All criteria must be true\n",
    "        return coin_strong and bench_weak and rs_strong\n",
    "    \n",
    "    # Apply outlier detection\n",
    "    df['Outlier'] = df.apply(is_outlier_row, axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3b80528-05c0-4dae-a0f2-5c9e47666137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_80324/4010749748.py:46: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(ticker_col, as_index=False, group_keys=False).apply(calc_aroon)\n"
     ]
    }
   ],
   "source": [
    "# Calculate all indicators using groupby\n",
    "grouped = data.groupby('Ticker')\n",
    "\n",
    "# RSI and change\n",
    "data['RSI'] = grouped['Close'].transform(lambda x: calculate_rsi(x))\n",
    "data['RSI_Chg'] = grouped['RSI'].diff()\n",
    "data['RSI_Divergence'] = grouped.apply(\n",
    "    lambda x: rsi_divergence(x, lookback=14), include_groups=False\n",
    ").reset_index(level=0, drop=True)\n",
    "\n",
    "# MACD\n",
    "data['EMA_12'] = grouped['Close'].transform(lambda x: x.ewm(span=12, adjust=False).mean())\n",
    "data['EMA_26'] = grouped['Close'].transform(lambda x: x.ewm(span=26, adjust=False).mean())\n",
    "data['MACD'] = data['EMA_12'] - data['EMA_26']\n",
    "data['MACD_Signal'] = grouped['MACD'].transform(lambda x: x.ewm(span=9, adjust=False).mean())\n",
    "data['MACD_Histogram'] = data['MACD'] - data['MACD_Signal']\n",
    "data['Prev_MACD'] = grouped['MACD'].transform(lambda x: x.shift(1))\n",
    "data['Prev_MACD_Signal'] = grouped['MACD_Signal'].transform(lambda x: x.shift(1))\n",
    "data['Prev_MACD_Histogram'] = grouped['MACD_Histogram'].transform(lambda x: x.shift(1))\n",
    "data = data.drop(['EMA_12', 'EMA_26'], axis=1)  # Clean up intermediate columns\n",
    "\n",
    "# Rate of Change (10-day)\n",
    "data['ROC'] = grouped['Close'].transform(lambda x: x.pct_change(periods=10))\n",
    "\n",
    "# Simple Moving Averages by X days\n",
    "for days in [10, 20, 50, 100, 150, 200, 250]:\n",
    "    data[f'SMA_{days}'] = grouped['Close'].transform(lambda x: x.rolling(window=days).mean())\n",
    "\n",
    "# Awesome Oscillator\n",
    "data['SMA_5'] = grouped['Close'].transform(lambda x: x.rolling(window=5).mean())\n",
    "data['SMA_34'] = grouped['Close'].transform(lambda x: x.rolling(window=34).mean())\n",
    "data['AO'] = data['SMA_5'] - data['SMA_34']\n",
    "data['AO_Chg'] = data.groupby('Ticker')['AO'].diff()\n",
    "data = data.drop(['SMA_5', 'SMA_34'], axis=1)  # Clean up intermediate columns\n",
    "\n",
    "# Close X days ago\n",
    "for days in [1, 2, 3, 4, 5]:\n",
    "    data[f'Close_{days}days_ago'] = grouped['Close'].shift(days)\n",
    "\n",
    "# Close change since yesterday\n",
    "data['Close_Chg'] = grouped['Close'].diff()\n",
    "data['Close_ChgPct'] = grouped['Close'].transform(lambda x: x.pct_change())\n",
    "\n",
    "# Volume X days ago\n",
    "for days in [1]:\n",
    "    data[f'Volume_{days}d_ago'] = grouped['Volume'].shift(days)\n",
    "\n",
    "# Volume change since yesterday\n",
    "data['Volume_Chg'] = grouped['Volume'].diff()\n",
    "data['Volume_ChgPct'] = grouped['Volume'].transform(lambda x: x.pct_change())\n",
    "\n",
    "# Aroon Up and Down\n",
    "data = add_aroon(data, period=14, ticker_col='Ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31c75366-f3fe-4ec8-b4a0-f124762ba265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_80324/1102290126.py:76: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(ticker_col, group_keys=False).apply(calc_dd_for_ticker)\n",
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_80324/43201852.py:141: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(ticker_col, group_keys=False).apply(calc_rs_for_ticker)\n"
     ]
    }
   ],
   "source": [
    "date_col = 'Date'\n",
    "ticker_col = 'Ticker'\n",
    "close_col = 'Close'\n",
    "\n",
    "# Drawdowns\n",
    "data = calculate_drawdowns(data, lookback_period=100, date_col=date_col, ticker_col=ticker_col, close_col=close_col)\n",
    "\n",
    "# Relative Strength\n",
    "data = calculate_relative_strength(data, benchmark_ticker = \"NDAQ\", lookback_period=7, \n",
    "                                date_col=date_col, ticker_col=ticker_col, close_col=close_col)\n",
    "\n",
    "# Outliers\n",
    "data = detect_outliers(data, benchmark_ticker = \"NDAQ\", date_col=date_col, ticker_col='Ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26514e66-e3d1-47ae-b9c1-4f3ed4c96928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data with indicators:\n",
      "         Date Ticker       Close        RSI      MACD      SMA_20  \\\n",
      "30 2022-12-13   AAPL  143.446945  42.356388 -1.263583  144.610532   \n",
      "31 2022-12-14   AAPL  141.218369  37.787409 -1.297658  144.273782   \n",
      "32 2022-12-15   AAPL  134.601669  33.843549 -1.837395  143.667827   \n",
      "33 2022-12-16   AAPL  132.639374  35.733163 -2.395863  142.868600   \n",
      "34 2022-12-19   AAPL  130.529129  36.714940 -2.974444  141.935755   \n",
      "35 2022-12-20   AAPL  130.460129  20.129152 -3.399356  141.161180   \n",
      "36 2022-12-21   AAPL  133.566284  27.979388 -3.445741  140.434923   \n",
      "37 2022-12-22   AAPL  130.391083  25.595171 -3.696107  139.506023   \n",
      "38 2022-12-23   AAPL  130.026230  26.261599 -3.879247  138.704824   \n",
      "39 2022-12-27   AAPL  128.221680  27.960259 -4.122478  138.005192   \n",
      "\n",
      "    Close_ChgPct  Volume_ChgPct  \n",
      "30      0.006782       0.332424  \n",
      "31     -0.015536      -0.123501  \n",
      "32     -0.046854       0.202217  \n",
      "33     -0.014579       0.618860  \n",
      "34     -0.015910      -0.503034  \n",
      "35     -0.000529      -0.027136  \n",
      "36      0.023809       0.109711  \n",
      "37     -0.023772      -0.093984  \n",
      "38     -0.002798      -0.180306  \n",
      "39     -0.013878       0.081374  \n",
      "\n",
      "\n",
      "All columns:\n",
      "['Date', 'Ticker', 'Close', 'High', 'Low', 'Open', 'Volume', 'RSI', 'RSI_Chg', 'RSI_Divergence', 'MACD', 'MACD_Signal', 'MACD_Histogram', 'Prev_MACD', 'Prev_MACD_Signal', 'Prev_MACD_Histogram', 'ROC', 'SMA_10', 'SMA_20', 'SMA_50', 'SMA_100', 'SMA_150', 'SMA_200', 'SMA_250', 'AO', 'AO_Chg', 'Close_1days_ago', 'Close_2days_ago', 'Close_3days_ago', 'Close_4days_ago', 'Close_5days_ago', 'Close_Chg', 'Close_ChgPct', 'Volume_1d_ago', 'Volume_Chg', 'Volume_ChgPct', 'Aroon_Up', 'Aroon_Down', 'Drawdown_%', 'RS_%', 'Benchmark_DD_%', 'Outlier']\n"
     ]
    }
   ],
   "source": [
    "# Display sample\n",
    "print(\"Sample data with indicators:\")\n",
    "print(data[data['Ticker'] == 'AAPL'].iloc[30:40][\n",
    "    ['Date', 'Ticker', 'Close', 'RSI', 'MACD', 'SMA_20', 'Close_ChgPct', 'Volume_ChgPct']\n",
    "])\n",
    "\n",
    "print(\"\\n\\nAll columns:\")\n",
    "print(data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6702594a-bf5f-49c2-b188-50b4ed4c84b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from last day\n",
    "lastday = data.loc[data.groupby('Ticker')['Date'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fd5aa20-bc14-40c7-9951-b42d8e986f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saved to TADASI_yhfinance.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Save\n",
    "excel_file = 'TADASI_yhfinance.xlsx'\n",
    "with pd.ExcelWriter(excel_file, engine='xlsxwriter') as writer:\n",
    "    ndaq100df.to_excel(writer, sheet_name='Tickers', index=False)\n",
    "    data.to_excel(writer, sheet_name='OHLC', index=False)\n",
    "    lastday.to_excel(writer, sheet_name='Last_Day', index=False)\n",
    "print(f\"\\n Saved to {excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "306dbd29-583d-46c1-8588-fa51f5f0927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ranaroussi/yfinance/issues/2469\n",
    "# import curl_cffi\n",
    "# session = curl_cffi.Session(impersonate=\"chrome\", timeout=5)\n",
    "# ticker = yf.Ticker('GBPEUR=X', session=session)\n",
    "# data = ticker.history(start='2025-05-05', end='2025-05-07')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722fde7b-bdc7-42f0-af82-0fb30cbd3ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
