{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "386d0bca-7073-432f-a327-34bf23dd0ba1",
   "metadata": {},
   "source": [
    "# Data Extraction from `yhfinance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb6c7eb7-5551-465d-8d20-76737438f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b345220-9770-499b-9fe4-eba0972f8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4c5bb2c-5359-4924-9c0d-b03ec19f5170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SAndP500_Wikipedia_Scrape():\n",
    "    \"\"\"\n",
    "    Fetch S&P500 tickers and corresponding data from Wikipedia\n",
    "    \"\"\"\n",
    "    print(\"Fetching from Wikipedia...\")\n",
    "    url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    # Download HTML, parse it to find all tables and create corresponding pandas DataFrames and return list of DataFrames\n",
    "    response = requests.get(url, headers=headers)\n",
    "    tables = pd.read_html(StringIO(response.text))\n",
    "    sp500_table = tables[0]\n",
    "    \n",
    "    # Create DataFrame with relevant info\n",
    "    df = pd.DataFrame({\n",
    "        'Ticker': sp500_table['Symbol'].tolist(),\n",
    "        'Company': sp500_table['Security'].tolist(),\n",
    "        'Sector': sp500_table['GICS Sector'].tolist(),\n",
    "        'Industry': sp500_table['GICS Sub-Industry'].tolist()\n",
    "    })\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f443982b-1634-4f03-85dc-1552e3704214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NASDAQ100_Wikipedia_Scrape():\n",
    "    \"\"\"\n",
    "    Fetch NASDAQ100 tickers and corresponding data from Wikipedia\n",
    "    \"\"\"\n",
    "    print(\"Fetching from Wikipedia...\")\n",
    "    url = 'https://en.wikipedia.org/wiki/Nasdaq-100'\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    \n",
    "    # Download HTML, parse it to find all tables and create corresponding pandas DataFrames and return list of DataFrames\n",
    "    response = requests.get(url, headers=headers)\n",
    "    tables = pd.read_html(StringIO(response.text))\n",
    "\n",
    "    # Find NASDAQ table\n",
    "    for index, table in enumerate(tables):\n",
    "        if 'Ticker' in table.columns and len(table) > 90:\n",
    "            ndaq100_table = tables[index]\n",
    "    \n",
    "    # Create DataFrame with relevant info\n",
    "    df = pd.DataFrame({\n",
    "        'Ticker': ndaq100_table['Ticker'].tolist(),\n",
    "        'Company': ndaq100_table['Company'].tolist(),\n",
    "        'Sector': ndaq100_table['ICB Sector'].tolist(),\n",
    "        'Industry': ndaq100_table['ICB Industry'].tolist()\n",
    "    })\n",
    "\n",
    "    # Add NDAQ manually\n",
    "    ndaq_row = pd.DataFrame({\n",
    "        'Ticker': [\"NDAQ\"],\n",
    "        'Company': [\"Nasdaq, Inc.\"],\n",
    "        'Sector': [\"Financial Services\"],\n",
    "        'Industry': [\"Stock Exchange\"]\n",
    "    })\n",
    "\n",
    "    df = pd.concat([df, ndaq_row], ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b9bfbfa-2221-4511-81be-6586db97ce5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching from Wikipedia...\n",
      " Successfully fetched 103 NASDAQ-100 tickers!\n",
      "\n",
      "============================================================\n",
      "Total tickers: 103\n",
      "\n",
      "First 10 tickers:\n",
      "Ticker                 Company                 Sector                        Industry\n",
      "  ADBE              Adobe Inc.             Technology               Computer Software\n",
      "   AMD  Advanced Micro Devices             Technology                  Semiconductors\n",
      "  ABNB                  Airbnb Consumer Discretionary Diversified Commercial Services\n",
      " GOOGL Alphabet Inc. (Class A) Communication Services               Computer Software\n",
      "  GOOG Alphabet Inc. (Class C) Communication Services               Computer Software\n",
      "  AMZN                  Amazon Consumer Discretionary  Catalog/Specialty Distribution\n",
      "   AEP American Electric Power              Utilities              Electric Utilities\n",
      "  AMGN                   Amgen            Health Care                   Biotechnology\n",
      "   ADI          Analog Devices             Technology                  Semiconductors\n",
      "  AAPL              Apple Inc.             Technology          Computer Manufacturing\n",
      "\n",
      "============================================================\n",
      "Sector Distribution:\n",
      "============================================================\n",
      "Sector\n",
      "Technology                43\n",
      "Consumer Discretionary    18\n",
      "Industrials               11\n",
      "Health Care               10\n",
      "Consumer Staples           6\n",
      "Utilities                  4\n",
      "Communication Services     3\n",
      "Telecommunications         3\n",
      "Real Estate                2\n",
      "Energy                     1\n",
      "Basic Materials            1\n",
      "Financial Services         1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ndaq100df = NASDAQ100_Wikipedia_Scrape()\n",
    "    ticker_list = ndaq100df['Ticker'].tolist()\n",
    "    print(f\" Successfully fetched {len(ndaq100df)} NASDAQ-100 tickers!\")\n",
    "    \n",
    "    # Display summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Total tickers: {len(ndaq100df)}\")\n",
    "    print(\"\\nFirst 10 tickers:\")\n",
    "    print(ndaq100df.head(10).to_string(index=False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Sector Distribution:\")\n",
    "    print(\"=\"*60)\n",
    "    print(ndaq100df['Sector'].value_counts())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Python scrape failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6503afcd-f74d-4195-85f9-f49f5bca2a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ticker_list = [\"AAPL\", \"META\", \"NDAQ\", \"SPY\",]\n",
    "# company_list = []\n",
    "\n",
    "# for ticker_symbol in ticker_list:\n",
    "#     try: \n",
    "#         stock = yf.Ticker(ticker_symbol)\n",
    "#         company_name = stock.info.get('longName', 'N/A')\n",
    "#         company_list.append(company_name)\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error fetching {ticker}: {e}\")\n",
    "#         company_list.append(\"Error\")\n",
    "\n",
    "# tick_comp_df = pd.DataFrame({\n",
    "#     'Ticker': ticker_list,\n",
    "#     'Company': company_list\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26536684-ed5b-4b0b-b71b-ee5c2a7157b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_31784/2776169727.py:3: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  data = yf.download(ticker_list, start=start_date, end=end_date, progress=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date Ticker       Close        High         Low        Open  \\\n",
      "0 2022-10-31   AAPL  150.957062  151.843085  149.559131  150.779866   \n",
      "1 2022-10-31   ABNB  106.910004  113.800003  106.669998  113.059998   \n",
      "2 2022-10-31   ADBE  318.500000  325.579987  317.420013  323.489990   \n",
      "3 2022-10-31    ADI  135.263504  136.458521  133.347708  136.392125   \n",
      "4 2022-10-31    ADP  226.601578  227.248477  224.501514  225.560916   \n",
      "5 2022-10-31   ADSK  214.300003  216.289993  214.000000  214.759995   \n",
      "6 2022-10-31    AEP   78.322487   79.632020   77.823620   79.596386   \n",
      "7 2022-10-31   AMAT   85.900406   86.980364   85.287460   86.454978   \n",
      "8 2022-10-31    AMD   60.060001   61.860001   59.529999   60.750000   \n",
      "9 2022-10-31   AMGN  245.694168  247.021009  243.558482  244.649053   \n",
      "\n",
      "       Volume  \n",
      "0  97943200.0  \n",
      "1  10733800.0  \n",
      "2   3253200.0  \n",
      "3   3078300.0  \n",
      "4   1711400.0  \n",
      "5    965000.0  \n",
      "6   4104000.0  \n",
      "7   6875400.0  \n",
      "8  73274100.0  \n",
      "9   3033600.0  \n"
     ]
    }
   ],
   "source": [
    "start_date = datetime.datetime(2022, 10, 29)\n",
    "end_date = datetime.datetime(2025, 10, 29)\n",
    "data = yf.download(ticker_list, start=start_date, end=end_date, progress=False)\n",
    "data = data.stack(level='Ticker', future_stack=True).reset_index()\n",
    "data.columns.name = None\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d149d89-3bda-4cdd-8d03-9a6d123d4d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate RSI\n",
    "def calculate_rsi(series, window=14):\n",
    "    delta = series.diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()\n",
    "    rs = gain / loss\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "# Function to calculate Aroon\n",
    "def add_aroon(data, period=14, ticker_col=None):\n",
    "    \"\"\"\n",
    "    Add Aroon Up and Aroon Down indicators to data\n",
    "    \n",
    "    Parameters:\n",
    "        data (DataFrame): Must have 'High' and 'Low' columns\n",
    "        period (int): Lookback period (default: 14)\n",
    "        ticker_col (str): Column name for ticker if multi-ticker data\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: Data with 'Aroon_Up' and 'Aroon_Down' columns added\n",
    "        \n",
    "    Note: Intermediate columns are automatically removed\n",
    "    \"\"\"\n",
    "    \n",
    "    df = data.copy()\n",
    "    \n",
    "    def calc_aroon(group):\n",
    "        # Periods since highest high\n",
    "        periods_high = group['High'].rolling(window=period).apply(\n",
    "            lambda x: period - 1 - np.argmax(x), raw=True\n",
    "        )\n",
    "        \n",
    "        # Periods since lowest low  \n",
    "        periods_low = group['Low'].rolling(window=period).apply(\n",
    "            lambda x: period - 1 - np.argmin(x), raw=True\n",
    "        )\n",
    "        \n",
    "        # Calculate Aroon indicators\n",
    "        group['Aroon_Up'] = ((period - periods_high) / period)\n",
    "        group['Aroon_Down'] = ((period - periods_low) / period)\n",
    "        \n",
    "        return group\n",
    "    \n",
    "    # Apply to each ticker or entire dataset\n",
    "    if ticker_col and ticker_col in df.columns:\n",
    "        df = df.groupby(ticker_col, as_index=False, group_keys=False).apply(calc_aroon)\n",
    "    else:\n",
    "        df = calc_aroon(df)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca4c5bd8-9257-40e9-abc7-77184fdb57e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect RSI divergence\n",
    "def rsi_divergence(group, lookback=14):\n",
    "    \"\"\"\n",
    "    Detect RSI divergence for each row in a group\n",
    "    Returns Series with divergence directions (1, -1, or 0)\n",
    "    \"\"\"\n",
    "    result = pd.Series(index=group.index, dtype=object)\n",
    "    \n",
    "    for i in range(len(group)):\n",
    "        # Need at least lookback periods\n",
    "        if i < lookback:\n",
    "            result.iloc[i] = None\n",
    "            continue\n",
    "        \n",
    "        # Get the lookback window (including current point)\n",
    "        start_idx = max(0, i - lookback)\n",
    "        price_window = group['Close'].iloc[start_idx:i+1]\n",
    "        rsi_window = group['RSI'].iloc[start_idx:i+1]\n",
    "        \n",
    "        # Current values\n",
    "        current_price = group['Close'].iloc[i]\n",
    "        current_rsi = group['RSI'].iloc[i]\n",
    "        \n",
    "        # Skip if RSI is NaN\n",
    "        if pd.isna(current_rsi):\n",
    "            result.iloc[i] = None\n",
    "            continue\n",
    "        \n",
    "        # Find min and max in the window (excluding current point)\n",
    "        price_window_prev = price_window.iloc[:-1]\n",
    "        rsi_window_prev = rsi_window.iloc[:-1]\n",
    "        \n",
    "        if len(price_window_prev) == 0:\n",
    "            result.iloc[i] = None\n",
    "            continue\n",
    "        \n",
    "        # Get indices of min/max\n",
    "        price_min_idx = price_window_prev.idxmin()\n",
    "        price_max_idx = price_window_prev.idxmax()\n",
    "        \n",
    "        # Bullish Divergence: Price making lower lows, RSI making higher lows\n",
    "        if price_min_idx != group.index[i]:  # Min is not at current point\n",
    "            prev_price_low = price_window_prev.loc[price_min_idx]\n",
    "            prev_rsi_at_price_low = group.loc[price_min_idx, 'RSI']\n",
    "            \n",
    "            if pd.notna(prev_rsi_at_price_low) and current_price < prev_price_low and current_rsi > prev_rsi_at_price_low:\n",
    "                result.iloc[i] = 1\n",
    "                continue\n",
    "        \n",
    "        # Bearish Divergence: Price making higher highs, RSI making lower highs\n",
    "        if price_max_idx != group.index[i]:  # Max is not at current point\n",
    "            prev_price_high = price_window_prev.loc[price_max_idx]\n",
    "            prev_rsi_at_price_high = group.loc[price_max_idx, 'RSI']\n",
    "            \n",
    "            if pd.notna(prev_rsi_at_price_high) and current_price > prev_price_high and current_rsi < prev_rsi_at_price_high:\n",
    "                result.iloc[i] = -1\n",
    "                continue\n",
    "        \n",
    "        result.iloc[i] = 0\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3b80528-05c0-4dae-a0f2-5c9e47666137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/136d3tf94ns_hpp_7z4mgphm0000gp/T/ipykernel_31784/4010749748.py:46: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df = df.groupby(ticker_col, as_index=False, group_keys=False).apply(calc_aroon)\n"
     ]
    }
   ],
   "source": [
    "# Calculate all indicators using groupby\n",
    "grouped = data.groupby('Ticker')\n",
    "\n",
    "# RSI and change\n",
    "data['RSI'] = grouped['Close'].transform(lambda x: calculate_rsi(x))\n",
    "data['RSI_Chg'] = grouped['RSI'].diff()\n",
    "data['RSI_Divergence'] = grouped.apply(\n",
    "    lambda x: rsi_divergence(x, lookback=14), include_groups=False\n",
    ").reset_index(level=0, drop=True)\n",
    "\n",
    "# MACD\n",
    "data['EMA_12'] = grouped['Close'].transform(lambda x: x.ewm(span=12, adjust=False).mean())\n",
    "data['EMA_26'] = grouped['Close'].transform(lambda x: x.ewm(span=26, adjust=False).mean())\n",
    "data['MACD'] = data['EMA_12'] - data['EMA_26']\n",
    "data['MACD_Signal'] = grouped['MACD'].transform(lambda x: x.ewm(span=9, adjust=False).mean())\n",
    "data['MACD_Histogram'] = data['MACD'] - data['MACD_Signal']\n",
    "data = data.drop(['EMA_12', 'EMA_26'], axis=1)  # Clean up intermediate columns\n",
    "\n",
    "# Rate of Change (10-day)\n",
    "data['ROC'] = grouped['Close'].transform(lambda x: x.pct_change(periods=10) * 100)\n",
    "\n",
    "# Simple Moving Averages by X days\n",
    "for days in [10, 20, 50, 100, 150, 200, 250]:\n",
    "    data[f'SMA_{days}'] = grouped['Close'].transform(lambda x: x.rolling(window=days).mean())\n",
    "\n",
    "# Awesome Oscillator\n",
    "data['SMA_5'] = grouped['Close'].transform(lambda x: x.rolling(window=5).mean())\n",
    "data['SMA_34'] = grouped['Close'].transform(lambda x: x.rolling(window=34).mean())\n",
    "data['AO'] = data['SMA_5'] - data['SMA_34']\n",
    "data['AO_Chg'] = data.groupby('Ticker')['AO'].diff()\n",
    "data = data.drop(['SMA_5', 'SMA_34'], axis=1)  # Clean up intermediate columns\n",
    "\n",
    "# Close X days ago\n",
    "for days in [1, 2, 3, 4, 5]:\n",
    "    data[f'Close_{days}days_ago'] = grouped['Close'].shift(days)\n",
    "\n",
    "# Close change since yesterday\n",
    "data['Close_Chg'] = grouped['Close'].diff()\n",
    "data['Close_ChgPct'] = grouped['Close'].transform(lambda x: x.pct_change() * 100)\n",
    "\n",
    "# Volume X days ago\n",
    "for days in [1]:\n",
    "    data[f'Volume_{days}d_ago'] = grouped['Volume'].shift(days)\n",
    "\n",
    "# Volume change since yesterday\n",
    "data['Volume_Chg'] = grouped['Volume'].diff()\n",
    "data['Volume_ChgPct'] = grouped['Volume'].transform(lambda x: x.pct_change() * 100)\n",
    "\n",
    "# Aroon Up and Down\n",
    "data = add_aroon(data, period=14, ticker_col='Ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26514e66-e3d1-47ae-b9c1-4f3ed4c96928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data with indicators:\n",
      "           Date Ticker       Close        RSI      MACD      SMA_20  \\\n",
      "3090 2022-12-13   AAPL  143.446945  42.356410 -1.263577  144.610533   \n",
      "3193 2022-12-14   AAPL  141.218353  37.787379 -1.297654  144.273781   \n",
      "3296 2022-12-15   AAPL  134.601669  33.843521 -1.837391  143.667826   \n",
      "3399 2022-12-16   AAPL  132.639359  35.733150 -2.395861  142.868599   \n",
      "3502 2022-12-19   AAPL  130.529114  36.714945 -2.974444  141.935754   \n",
      "3605 2022-12-20   AAPL  130.460114  20.128988 -3.399357  141.161179   \n",
      "3708 2022-12-21   AAPL  133.566299  27.979379 -3.445740  140.434924   \n",
      "3811 2022-12-22   AAPL  130.391083  25.595122 -3.696106  139.506024   \n",
      "3914 2022-12-23   AAPL  130.026245  26.261589 -3.879245  138.704825   \n",
      "4017 2022-12-27   AAPL  128.221680  27.960206 -4.122475  138.005193   \n",
      "\n",
      "      Close_ChgPct  Volume_ChgPct  \n",
      "3090      0.678247      33.242411  \n",
      "3193     -1.553600     -12.350058  \n",
      "3296     -4.685428      20.221725  \n",
      "3399     -1.457865      61.886004  \n",
      "3502     -1.590964     -50.303359  \n",
      "3605     -0.052862      -2.713569  \n",
      "3708      2.380947      10.971061  \n",
      "3811     -2.377259      -9.398450  \n",
      "3914     -0.279803     -18.030599  \n",
      "4017     -1.387847       8.137441  \n",
      "\n",
      "\n",
      "All columns:\n",
      "['Date', 'Ticker', 'Close', 'High', 'Low', 'Open', 'Volume', 'RSI', 'RSI_Chg', 'RSI_Divergence', 'MACD', 'MACD_Signal', 'MACD_Histogram', 'ROC', 'SMA_10', 'SMA_20', 'SMA_50', 'SMA_100', 'SMA_150', 'SMA_200', 'SMA_250', 'AO', 'AO_Chg', 'Close_1days_ago', 'Close_2days_ago', 'Close_3days_ago', 'Close_4days_ago', 'Close_5days_ago', 'Close_Chg', 'Close_ChgPct', 'Volume_1d_ago', 'Volume_Chg', 'Volume_ChgPct', 'Aroon_Up', 'Aroon_Down']\n"
     ]
    }
   ],
   "source": [
    "# Display sample\n",
    "print(\"Sample data with indicators:\")\n",
    "print(data[data['Ticker'] == 'AAPL'].iloc[30:40][\n",
    "    ['Date', 'Ticker', 'Close', 'RSI', 'MACD', 'SMA_20', 'Close_ChgPct', 'Volume_ChgPct']\n",
    "])\n",
    "\n",
    "print(\"\\n\\nAll columns:\")\n",
    "print(data.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6702594a-bf5f-49c2-b188-50b4ed4c84b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from last day\n",
    "lastday = data.loc[data.groupby('Ticker')['Date'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fd5aa20-bc14-40c7-9951-b42d8e986f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Saved to TADASI_yhfinance.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Save\n",
    "excel_file = 'TADASI_yhfinance.xlsx'\n",
    "with pd.ExcelWriter(excel_file, engine='xlsxwriter') as writer:\n",
    "    ndaq100df.to_excel(writer, sheet_name='Tickers', index=False)\n",
    "    data.to_excel(writer, sheet_name='OHLC', index=False)\n",
    "    lastday.to_excel(writer, sheet_name='Last_Day', index=False)\n",
    "print(f\"\\n Saved to {excel_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "306dbd29-583d-46c1-8588-fa51f5f0927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ranaroussi/yfinance/issues/2469\n",
    "# import curl_cffi\n",
    "# session = curl_cffi.Session(impersonate=\"chrome\", timeout=5)\n",
    "# ticker = yf.Ticker('GBPEUR=X', session=session)\n",
    "# data = ticker.history(start='2025-05-05', end='2025-05-07')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722fde7b-bdc7-42f0-af82-0fb30cbd3ace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
